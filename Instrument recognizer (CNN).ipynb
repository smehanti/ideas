{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(\n",
    "rescale=1./255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=train_datagen.flow_from_directory(\n",
    "'/Users/saurabhmehanti/Desktop/Training_set',\n",
    "target_size=(64,64),\n",
    "batch_size=32,\n",
    "class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu',input_shape=[64,64,3]))\n",
    "\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# second layer\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "\n",
    "# third layer\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# flattening\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# full connection\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=120,activation='relu'))\n",
    "\n",
    "# output layer\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=16, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling\n",
    "\n",
    "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(training_set,epochs=60,steps_per_epoch=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=image.load_img('/Users/saurabhmehanti/Desktop/test_tabla2.jpg', target_size=[64,64])\n",
    "test_img=image.img_to_array(test_img)\n",
    "test_img=np.expand_dims(test_img, axis=0)\n",
    "result=cnn.predict(test_img)\n",
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if result[0][0]==0:\n",
    "    pred='accordian'\n",
    "    \n",
    "elif result[0][0]==[[0.1]]:\n",
    "    pred='bagpiper'\n",
    "    \n",
    "elif result[0][0]==2:\n",
    "    pred='banjo'\n",
    "    \n",
    "elif result[0][0]==3:\n",
    "    pred='conga'\n",
    "    \n",
    "elif result[0][0]==4:\n",
    "    pred='dholak'\n",
    "    \n",
    "elif result[0][0]==5:\n",
    "    pred='drum'\n",
    "    \n",
    "elif result[0][0]==6:\n",
    "    pred='flute'\n",
    "    \n",
    "elif result[0][0]==7:\n",
    "    pred='guitar'\n",
    "    \n",
    "elif result[0][0]==8:\n",
    "    pred='harp'\n",
    "    \n",
    "elif result[0][0]==9:\n",
    "    pred='mouth organ'\n",
    "    \n",
    "elif result[0][0]==10:\n",
    "    pred='piano'\n",
    "    \n",
    "elif result[0][0]==11:\n",
    "    pred='saxophone'\n",
    "    \n",
    "elif result[0][0]==12:\n",
    "    pred='sitar'\n",
    "    \n",
    "elif result[0][0]==13:\n",
    "    pred='tabla'\n",
    "    \n",
    "elif result[0][0]==14:\n",
    "    pred='trumpet'\n",
    "    \n",
    "elif result[0][0]==15:\n",
    "    pred='violin'\n",
    "    \n",
    "print(pred, result,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
